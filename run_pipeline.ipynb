{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from pystackreg import StackReg\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import utils as utl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of channels and z slices\n",
    "n_ch, n_z = 2, 15\n",
    "# frequencies used for imaging, ball velocities, and behavior\n",
    "f_ca, f_ball, f_beh = 2, 50, 200\n",
    "\n",
    "# transformation used for registration https://pystackreg.readthedocs.io/en/latest/readme.html#usage\n",
    "reg = StackReg.SCALED_ROTATION \n",
    "\n",
    "# path to folder\n",
    "parent_dir = Path(r'\\\\mpfi.org\\public\\sb-lab\\Nino_2P_for_Salil\\for_Nico\\stop1_imaging\\stop1-GCaMP6f-tdTomato_VNC')\n",
    "\n",
    "# selection rule for tif files\n",
    "p_tifs = parent_dir.glob('**/trials_to_register/*/trial*_000??.tif')\n",
    "\n",
    "# folders to skip\n",
    "skip = [\n",
    "    r'\\\\mpfi.org\\public\\sb-lab\\Nino_2P_for_Salil\\for_Nico\\stop1_imaging\\stop1-GCaMP6f-tdTomato_VNC\\fed\\female1\\trials_to_register\\trial9_00001',\n",
    "    r'\\\\mpfi.org\\public\\sb-lab\\Nino_2P_for_Salil\\for_Nico\\stop1_imaging\\stop1-GCaMP6f-tdTomato_VNC\\fed\\female1\\trials_to_register\\trial8_00001',\n",
    "]\n",
    "skip = [ Path(p) for p in skip ]\n",
    "p_tifs = [ p for p in p_tifs if p.parent not in skip ]\n",
    "\n",
    "# collect all data\n",
    "p_all = Path('./all_data.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_tif in p_tifs:\n",
    "    print()\n",
    "    \n",
    "    p_out =  lambda x: p_tif.parent / '{}_{}'.format(p_tif.with_suffix('').name, x)\n",
    "\n",
    "    if p_out('ch1.tif').is_file():\n",
    "        print(f'INFO output file exists, skipping registration for {p_tif.parent}')\n",
    "        continue\n",
    "        \n",
    "    print(f'INFO registering {p_tif}')\n",
    "\n",
    "    # load\n",
    "    stack = utl.load_tiff(p_tif)\n",
    "    ch1, ch2 = utl.split_channels(stack, n_z=15, n_ch=2)\n",
    "    ch1 = utl.maxproj_z(ch1)\n",
    "    ch2 = utl.maxproj_z(ch2)\n",
    "\n",
    "    # register\n",
    "    tmats = utl.get_tmats(ch2, reg)\n",
    "    ch1_a = utl.align(ch1, tmats, reg)\n",
    "    ch2_a = utl.align(ch2, tmats, reg)\n",
    "\n",
    "    # mean image\n",
    "    ch1_am = np.mean(ch1_a, axis=0)\n",
    "    ch2_am = np.mean(ch2_a, axis=0)\n",
    "\n",
    "    # save to disk\n",
    "    utl.write_tif(p_out('ch1.tif'), ch1_a.astype('int16'))\n",
    "    utl.write_tif(p_out('ch2.tif'), ch2_a.astype('int16'))\n",
    "\n",
    "    utl.write_tif(p_out('ch1reg.tif'), ch1_a.astype('int16'))\n",
    "    utl.write_tif(p_out('ch2reg.tif'), ch2_a.astype('int16'))\n",
    "\n",
    "    utl.save_img(p_out('ch1mean.bmp'), ch1_am)\n",
    "    utl.save_img(p_out('ch2mean.bmp'), ch2_am)\n",
    "\n",
    "    utl.save_dual_movie(p_out('ch1ch2.mp4'), ch1, ch2)\n",
    "    utl.save_dual_movie(p_out('ch1reg.mp4'), ch1, ch1_a)\n",
    "    utl.save_dual_movie(p_out('ch2reg.mp4'), ch2, ch2_a)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: ROI extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_tif in p_tifs:\n",
    "    print()\n",
    "    \n",
    "    p_out =  lambda x: p_tif.parent / '{}_{}'.format(p_tif.with_suffix('').name, x)\n",
    "\n",
    "    # check if ROI traces have already been extracted\n",
    "    p_roi = p_out('roi_traces.npy')\n",
    "    if p_roi.is_file():\n",
    "        print(f'INFO output files exists, skipping ROI extraction for {p_tif.parent}')\n",
    "        continue\n",
    "\n",
    "    # check if only one RoiSet.zip file is present\n",
    "    l_zip = [ *p_tif.parent.glob('*RoiSet.zip') ]\n",
    "    if len(l_zip) == 0:\n",
    "        print(f'INFO no *RoiSet.zip file found. Skipping {p_tif.parent}')\n",
    "        continue\n",
    "    elif len(l_zip) > 1:\n",
    "        print(f'WARNING folder must contain no more than one `*RoiSet.zip` file: skipping {p_tif.parent}')\n",
    "        continue\n",
    "\n",
    "    p_zip = l_zip[0]\n",
    "    print(f'INFO loading ROIs from {p_zip}')\n",
    "\n",
    "    # load aligned ch1\n",
    "    stack = utl.load_tiff(p_out('ch1reg.tif'))\n",
    "    img = np.mean(stack, axis=0)\n",
    "\n",
    "    # load ROIs\n",
    "    rois = utl.read_imagej_rois(p_zip, img)\n",
    "    img_rois = utl.draw_rois(img, rois)\n",
    "    utl.save_img(p_out('ch1mean_rois.bmp'), img_rois)\n",
    "\n",
    "    # extract traces\n",
    "    ca = utl.get_mean_trace(rois, stack, subtract_background=True, sigma=0)\n",
    "    np.save(p_roi, ca)    \n",
    "    print(f'INFO saving ROI traces to {p_roi}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_tif in p_tifs:\n",
    "    print()\n",
    "    \n",
    "    p_out =  lambda x: p_tif.parent / '{}_{}'.format(p_tif.with_suffix('').name, x)\n",
    "\n",
    "    p_df = p_out('data.parquet')\n",
    "\n",
    "    if p_df.is_file():\n",
    "        print(f'INFO output files exists, skipping data merging for {p_tif.parent}')\n",
    "        continue\n",
    "\n",
    "    # load ROI traces\n",
    "    p_roi = p_out('roi_traces.npy')\n",
    "    if not p_roi.is_file():\n",
    "        print(f'INFO file with ROI traces not found, skipping {p_tif.parent}')\n",
    "    else:\n",
    "        ca = np.load(p_roi)\n",
    "\n",
    "    # load behavior data\n",
    "    p_ball = p_tif.parent / (p_tif.name.split('_')[0] + '.mat')\n",
    "    l_act = [*p_tif.parent.glob('*-actions.mat')]\n",
    "    if not (p_ball.is_file() and len(l_act) == 1):\n",
    "        print(f'INFO matlab files missing or incorrect name: skipping {p_tif.parent}')\n",
    "        continue\n",
    "\n",
    "        \n",
    "    ball = utl.load_ball(p_ball)\n",
    "\n",
    "    p_beh = l_act[0]\n",
    "    beh = utl.load_behavior(p_beh)\n",
    "\n",
    "    df = utl.upsample_to_behavior(ca, beh, ball, f_ca, f_ball, f_beh)\n",
    "\n",
    "    df = utl.zscore_rois(df)\n",
    "\n",
    "    df = utl.convolute_ca_kernel(df, f=f_beh)\n",
    "\n",
    "    pt = p_tif.parts\n",
    "    cond, fly, trial = pt[-5], pt[-4], pt[-2]\n",
    "    df.loc[:, 'cond'] = cond\n",
    "    df.loc[:, 'fly'] = fly\n",
    "    df.loc[:, 'trial'] = trial\n",
    "    print(f'INFO parsing folder names: fly {fly} | trial {trial} | condition {cond}')\n",
    "\n",
    "    # plot data\n",
    "    utl.plot_data(df, f_beh, path=p_out('data.png'))\n",
    "    # plot pearson r heatmap\n",
    "    utl.plot_corr_heatmap(df, path=p_out('heatmap.png'))\n",
    "    # plot ccf\n",
    "    utl.plot_ccf(df, f=f_beh, pool_fly=True, path=p_out('ccf.png'))\n",
    "\n",
    "    print(f'INFO writing merged data to {p_df}')\n",
    "    df.to_parquet(p_df)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: merge all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all trials and flies\n",
    "\n",
    "g = parent_dir.glob('**/trials_to_register/*/*_data.parquet')\n",
    "\n",
    "l = []\n",
    "for f in g:  \n",
    "    print()\n",
    "    \n",
    "    print(f'INFO loading file {f}')\n",
    "    d = pd.read_parquet(f)\n",
    "    l.append(d)\n",
    "\n",
    "print(f'INFO writing all data to {p_all}')\n",
    "df = pd.concat(l, ignore_index=True)\n",
    "df.to_parquet(p_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from disk\n",
    "df = pd.read_parquet(p_all)\n",
    "print('INFO dataframe contains')\n",
    "for f, d in df.groupby('fly'):\n",
    "    print(f'     {f}', end=': ')\n",
    "    for t, _ in d.groupby('trial'):\n",
    "        print(f'{t}', end=' ')\n",
    "    print()\n",
    "\n",
    "# plot averages\n",
    "utl.plot_corr_heatmap(df, path=p_all.parent / 'heatmap.png')\n",
    "utl.plot_ccf(df, f=f_beh, pool_fly=True,  path=p_all.parent / 'ccf.png')\n",
    "utl.plot_ccf(df, f=f_beh, pool_fly=False, path=p_all.parent / 'ccf_indv.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
