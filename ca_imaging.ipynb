{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pystackreg import StackReg\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import utils as utl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of channels and z slices\n",
    "n_ch, n_z = 2, 15\n",
    "# smoothing in xy before registration (sigma 2D Gaussian)\n",
    "xy_smth = 4\n",
    "\n",
    "# frequencies used for imaging, ball velocities, and behavior\n",
    "f_ca, f_ball, f_beh = 2, 50, 200\n",
    "\n",
    "# transformation used for registration https://pystackreg.readthedocs.io/en/latest/readme.html#usage\n",
    "reg = StackReg.SCALED_ROTATION \n",
    "\n",
    "# path to folder\n",
    "parent_dir = Path(r'\\\\mpfi.org\\public\\sb-lab\\Nino_2P_for_Salil\\for_Nico\\stop1_imaging\\stop1-GCaMP6f-tdTomato_VNC_smth8')\n",
    "\n",
    "# selection rule for tif files\n",
    "p_tifs = [ *parent_dir.glob('**/trials_to_register/*/trial*_00???.tif') ]\n",
    "\n",
    "# force overwriting files\n",
    "overwrite = True\n",
    "\n",
    "# folder to save output\n",
    "p_out = parent_dir / 'pipeline_output'\n",
    "p_out.mkdir(exist_ok=True)\n",
    "p_all = p_out / 'all_data.parquet'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# general processing pipeline\n",
    "## Step 1: Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_tif in p_tifs:\n",
    "    print()\n",
    "\n",
    "    if utl.fname(p_tif, 'ch1.tif').is_file() and not overwrite:\n",
    "        print(f'INFO output file exists, skipping registration for {p_tif.parent}')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'INFO now registering {p_tif}')\n",
    "\n",
    "    # load and split\n",
    "    stack = utl.load_tiff(p_tif)\n",
    "    ch1, ch2 = utl.split_channels(stack, n_z=15, n_ch=2)\n",
    "    ch1 = utl.maxproj_z(ch1)\n",
    "    ch2 = utl.maxproj_z(ch2)\n",
    "\n",
    "    ch1 = utl.smooth_xy(ch1, xy_smth)\n",
    "    ch2 = utl.smooth_xy(ch2, xy_smth)\n",
    "\n",
    "    # register\n",
    "    tmats = utl.get_tmats(ch2, reg)\n",
    "    ch1_a = utl.align(ch1, tmats, reg)\n",
    "    ch2_a = utl.align(ch2, tmats, reg)\n",
    "\n",
    "    # mean image\n",
    "    ch1_am = np.mean(ch1_a, axis=0)\n",
    "    ch2_am = np.mean(ch2_a, axis=0)\n",
    "\n",
    "    # save to disk\n",
    "    utl.write_tif(utl.fname(p_tif, 'ch1.tif'), ch1_a.astype('int16'))\n",
    "    utl.write_tif(utl.fname(p_tif, 'ch2.tif'), ch2_a.astype('int16'))\n",
    "\n",
    "    utl.write_tif(utl.fname(p_tif, 'ch1reg.tif'), ch1_a.astype('int16'))\n",
    "    utl.write_tif(utl.fname(p_tif, 'ch2reg.tif'), ch2_a.astype('int16'))\n",
    "\n",
    "    utl.save_img(utl.fname(p_tif, 'ch1mean.bmp'), ch1_am)\n",
    "    utl.save_img(utl.fname(p_tif, 'ch2mean.bmp'), ch2_am)\n",
    "\n",
    "    utl.save_dual_movie(utl.fname(p_tif, 'ch1ch2.mp4'), ch1, ch2)\n",
    "    utl.save_dual_movie(utl.fname(p_tif, 'ch1reg.mp4'), ch1, ch1_a)\n",
    "    utl.save_dual_movie(utl.fname(p_tif, 'ch2reg.mp4'), ch2, ch2_a)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ROI extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_tif in p_tifs:\n",
    "    print()\n",
    "    \n",
    "    # check if ROI traces have already been extracted\n",
    "    p_roi = utl.fname(p_tif, 'roi_traces.npy')\n",
    "    if p_roi.is_file() and not overwrite:\n",
    "        print(f'INFO output files exists, skipping ROI extraction for {p_tif.parent}')\n",
    "        continue\n",
    "\n",
    "    # load Roi.zip\n",
    "    p_zip = utl.get_roi_zip_file(p_tif)\n",
    "    if not p_zip:\n",
    "        print(f'WARNING Skipping {p_tif.parent}')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'INFO loading ROIs from {p_zip}')\n",
    "\n",
    "    # load aligned ch1\n",
    "    stack = utl.load_tiff(utl.fname(p_tif, 'ch1reg.tif'))\n",
    "    # stack = utl.load_tiff(utl.fname(p_tif, 'ch2reg.tif'))\n",
    "    img = np.mean(stack, axis=0)\n",
    "\n",
    "    # load ROIs\n",
    "    rois = utl.read_imagej_rois(p_zip, img)\n",
    "    img_rois = utl.draw_rois(img, rois)\n",
    "    utl.save_img(utl.fname(p_tif, 'ch1mean_rois.bmp'), img_rois)\n",
    "\n",
    "    # extract traces\n",
    "    ca = utl.get_mean_trace(rois, stack, subtract_background=True, sigma=0)\n",
    "    np.save(p_roi, ca)    \n",
    "    print(f'INFO saving ROI traces to {p_roi}')  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Combine imaging and behavior data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_tif in p_tifs:\n",
    "    print()\n",
    "    \n",
    "    # check if already been processed\n",
    "    p_df = utl.fname(p_tif, 'data.parquet')\n",
    "    if p_df.is_file() and not overwrite:\n",
    "        print(f'INFO output files exists, skipping data merging for {p_tif.parent}')\n",
    "        continue\n",
    "\n",
    "    # load ROI traces\n",
    "    p_roi = utl.fname(p_tif, 'roi_traces.npy')\n",
    "    if not p_roi.is_file():\n",
    "        print(f'WARNING file with ROI traces not found, skipping {p_tif.parent}')\n",
    "    else:\n",
    "        ca = np.load(p_roi)\n",
    "\n",
    "    # load behavior data and ball velocities\n",
    "    p_mats = utl.get_matlab_files(p_tif)\n",
    "    if not p_mats:\n",
    "        print(f'WARNING skipping {p_tif.parent}')\n",
    "    else:\n",
    "        p_ball, p_beh =  p_mats\n",
    "        \n",
    "    ball = utl.load_ball(p_ball)\n",
    "    beh = utl.load_behavior(p_beh)\n",
    "\n",
    "    # match sample rates\n",
    "    df = utl.upsample_to_behavior(ca, beh, ball, f_ca, f_ball, f_beh)\n",
    "    # zscore ROIs\n",
    "    df = utl.zscore_cols(df, col_start='roi_')\n",
    "    # convolute ball velocities and behavior with Ca kernel\n",
    "    df = utl.convolute_ca_kernel(df, f=f_beh)\n",
    "    # zscore ball velocities\n",
    "    df = utl.zscore_cols(df, col_start='conv_ball_')\n",
    "\n",
    "    # add additional data based on file and folder names\n",
    "    pt = p_tif.parts\n",
    "    cond, fly, trial = pt[-5], pt[-4], pt[-2]\n",
    "    df.loc[:, 'cond'] = cond # e.g. fed/starved\n",
    "    df.loc[:, 'fly'] = fly # fly number\n",
    "    df.loc[:, 'trial'] = trial # trial number\n",
    "    print(f'INFO parsing folder names: fly {fly} | trial {trial} | condition {cond}')\n",
    "\n",
    "    # plots for quality control\n",
    "    utl.plot_data(df, f_beh, path=utl.fname(p_tif, 'data.png'))\n",
    "    # pearson r heatmap\n",
    "    utl.plot_corr_heatmap(df, beh='behi', path=utl.fname(p_tif, 'heatmap.png'))\n",
    "    # ccf\n",
    "    utl.plot_ccf(df, f=f_beh, pool_fly=True, path=utl.fname(p_tif, 'ccf.png'))\n",
    "\n",
    "    # save to disk\n",
    "    print(f'INFO writing merged data to {p_df}')\n",
    "    df.to_parquet(p_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: merge all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all trials and flies\n",
    "\n",
    "# list of all *_data.parquet files\n",
    "p_pars = [ utl.fname(p, 'data.parquet') for p in p_tifs ]\n",
    "\n",
    "l = []\n",
    "for p_par in p_pars:\n",
    "    print()\n",
    "    if not p_par.is_file():\n",
    "        print(f'WARNING skipping {p_par.parent}')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'INFO loading file {p_par}')\n",
    "        df = pd.read_parquet(p_par)\n",
    "        l.append(df)\n",
    "\n",
    "# combine dataframes and save\n",
    "df = pd.concat(l, ignore_index=True)\n",
    "df.to_parquet(p_all)\n",
    "\n",
    "print(f'INFO contents of {p_all}')\n",
    "for f, d in df.groupby('fly'):\n",
    "    print(f'     {f}', end=': ')\n",
    "    for t, _ in d.groupby('trial'):\n",
    "        print(f'{t}', end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from disk\n",
    "df = pd.read_parquet(p_all)\n",
    "df = df.fillna(0) # TODO workaround because of missing behavior\n",
    "\n",
    "# optional: remove ROI 7, 8, 9\n",
    "df = df.drop(columns=['z_roi_7', 'z_roi_8', 'z_roi_9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson's R heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson correlation heatmap (selection of columns: see utl.calculate_pearson)\n",
    "utl.plot_corr_heatmap(df, beh='behi', path=p_out / 'heatmap.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson heatmaps around behavior events\n",
    "dt = 5 # time in s to keep before and after behavior event\n",
    "\n",
    "# loop through all behavior\n",
    "cols = [ c for c in df.columns if c.startswith('beh_') ]\n",
    "for col in cols:\n",
    "\n",
    "    # select df around behavoir\n",
    "    d = utl.select_event(df, col, f_beh, dt)\n",
    "\n",
    "    # generate plot\n",
    "    utl.plot_corr_heatmap(d, beh='behi', path=p_out / f'heatmap_{col}.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### behavior/ball and ROI cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-correlation functions behavior/ball and ROIs (averaged)\n",
    "utl.plot_ccf(df, f=f_beh, pool_fly=True,  path=p_out / 'ccf.svg')\n",
    "\n",
    "# same (not averaged)\n",
    "utl.plot_ccf(df, f=f_beh, pool_fly=False, path=p_out / 'ccf_indv.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average ROIs and ball velocities aligned to behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 5 # time in s before and after behavior event\n",
    "s = 0.25 # smoothing window for velocity [in s] \n",
    "\n",
    "# smooth velocity\n",
    "df_ = df.copy()\n",
    "df_.loc[:, ['ball_x', 'ball_y', 'ball_z']] = gaussian_filter(df_.loc[:, ['ball_x', 'ball_y', 'ball_z']].values, (s * f_beh, 0))\n",
    "\n",
    "# cycle through all behavoirs\n",
    "cols = [c for c in df_.columns if c.startswith('beh_')]\n",
    "for col in cols:\n",
    "\n",
    "    # align to behavior\n",
    "    df_al = utl.align2events(df_, col, f_beh, dt)\n",
    "\n",
    "    utl.plot_aligned(df_al, path=p_out / f'aligned_to_{col}.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## individual recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tif file for session of interest\n",
    "p_tifs = [ *Path(r'Y:\\Nino_2P_for_Salil\\for_Nico\\stop1_imaging\\stop1-GCaMP6f-tdTomato_VNC\\fed\\female13\\trials_to_register').glob('**/*_000??.tif') ]\n",
    "p_tif = p_tifs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and create output folder\n",
    "p_out = p_tif.parent / 'corrmap'\n",
    "p_out.mkdir(exist_ok=True)\n",
    "\n",
    "# load registered tif files and smooth x/y\n",
    "ch1 = utl.load_tiff(utl.fname(p_tif, 'ch1reg.tif'))\n",
    "ch2 = utl.load_tiff(utl.fname(p_tif, 'ch2reg.tif'))\n",
    "arr1 = gaussian_filter(ch1, sigma=(0, 1, 1))\n",
    "arr2 = gaussian_filter(ch2, sigma=(0, 1, 1))\n",
    "\n",
    "# load preprocessed behavior data\n",
    "df = pd.read_parquet(utl.fname(p_tif, 'data.parquet'))\n",
    "\n",
    "# loop through all conv behi and conv ball columns\n",
    "cols = [ c for c in df.columns if c.startswith('conv_behi') or c.startswith('conv_ball') ]\n",
    "for col in cols:\n",
    "    utl.plot_corrmap(arr1, arr2, df, col, f_ca=f_ca, f_beh=f_beh, path=p_out / f'{col}_1xy.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
